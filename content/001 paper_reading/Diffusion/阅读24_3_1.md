# DDM
> quote from Yang Song
> ![[Pasted image 20240116102851.png]]
## BG

+ generated by latent variable $z$
+ generally learn low-dim latent representations
### ELBO

1. $p(x,z)$: model the latent variable and the data, likelihood-based: maximize the likelihood $p(x)$.
2. ![[Pasted image 20231129170724.png|150]]![[Pasted image 20231129170731.png|150]]

3. 推导evidence lower bound:（VLB/ELBO)
	1. ![[Pasted image 20231129171149.png]]KL大于0, $q_\phi(z|x)$: the approximate posterior.p(x):likelihood of observed or generated data   当KL趋近于0意味着logp(x)接近于ELBO式。如果减小KL距离，则q接近真实后验分布。但因为我们不知道真实后验，所以KL很难计算。而左侧p(x)与参数$\phi$无关，所以optimize ELBO就等于使得估计的后验 接近真实的后验。并且因为KL趋近于0，可以用ELBO估计p(x)

### VAE
![[Pasted image 20240223102231.png]]
1. maximize ELBO
	1. ![[Pasted image 20231129172419.png]]
		 encoder learn $q$, decoder learn $p$
		+ reconstruction likelihood of decoder:确保decoder对latent有效建模
		+ 学习到的 z 分布（variational distribution) （q(z|x))和先验相似程度。确保encoder有效建模而不是一个Dirac函数
3. encoder: 学习一个multi gaussion, 假设prior是standard gaussion:
	1. ![[Pasted image 20231129173604.png]]
	2. reconstruction term 可以用monte varlo估计，latents ${z^{(l)}}^L_{l=1}$  are sampled from $q_\phi(z|x)$ .单纯sample是不可导的-> reparamterization trick
	3.  reparamterization trick: 将r.v.重写做noise variable函数，从而化为从一个standard gaussioan 中sample,能够对参数做gradient descent.(注意 $\odot$ element-wise product)
		![[Pasted image 20231129174306.png|300]]
	1. VAE中 z dim 小于x->学到compact latent vector, 可修改latent vector控制生成
	

### HVAE
将前向反向都看作为马尔科夫链： decoding each latent $z_t$ only conditions on previous latent $z_{t+1}$, 低级依赖高级

![[Pasted image 20231129205321.png]]
![[Pasted image 20231129205331.png]]
Lower-bound:
![[Pasted image 20231129205414.png]]


## Variational Diffusion Models
![[Pasted image 20231129205937.png]]
1. 与HVAE不同
	1. latent dim = data dim （所以latent 和data 都写作$x_t$ ） 
	2. at t, the latent encoder is defined as a linear Gaussian model
	3. The Gaussian parameter of latent encoder vary -> at final T, standard Gaussian
2. the distribution of each latent variable in the encoder is a Gaussian centered around its previous hierarchical latent. 
	1. ![[Pasted image 20231129210136.png|307]]
	2. linear Gaussian parameters: hyperparameters or learned 
	3. ![[Pasted image 20231130091907.png]]![[Pasted image 20231130091914.png]]
	4. ![[Pasted image 20231130091944.png]]
	5. ![[Pasted image 20231130092041.png]]
	6. 不同于HVAE, encoder过程没有参数 $\phi$ ,每一步为Gaussian. 我们关心 $p_\theta(x_{t-1}|x_t)$ 以生成新的$x_0$.
3. ELBO式子
	1. ![[Pasted image 20231130093329.png]]
		1. reconstruction: 
		2. prior matching : 不用优化，没有learnable parameters, 足够大T可以使最后为gaussian, 这一项变为0
		3. consistency term: 因此主要优化第三个式子, 然而使用Monte Carlo涉及两个r.v. $x_{t-1},x_{t+1}$ , 会变得不稳定（这两个随机变量噪声叠加，最终估计的是加上所有采样，所以variance 会高）
		4. 由于$q(x_{t-1}|x_t) = \int q(x_0)q(x_{t-1}|x_t, x_0) dx_0$无法求（注：推导 :$q(x_{t-1}|x_t,x_0)$是 given $x_t,x_0$，如果将$q(x_{t-1}|x_t,x_0)$看作 $q(A|B)$ 那么后面就是边缘概率的积分） 利用markov化为另一种形式![[Pasted image 20231130094503.png]]![[Pasted image 20231130094516.png]]
				1. 最后一项：denosing matching. 希望denosing transition step $p_\theta(x_{t-1}|x_t)$ 和 ground-truth denosing transition step $q(x_{t-1}|x_t,x_0)$越接近越好。其中在HVAE由于本身encoder learning复杂因此$q(x_{t-1}|x_t,x_0)$不好计算，而在VDM中可以利用gaussian性质简化：
					1. ![[Pasted image 20231130095509.png]]  这样可以用markov, 只需要找到$q(x_{t-1}|x_0),q(x_t|x_0)$就可以。  
					2. ![[Pasted image 20231130095345.png]]![[Pasted image 20231130095444.png]]
					3. $q(x_{t-1}|x_t,x_0)$最终化为![[Pasted image 20231130095816.png]]
				2. 由于 希望denosing transition step $p_\theta(x_{t-1}|x_t)$ 和 ground-truth denosing transition step $q(x_{t-1}|x_t,x_0)$越接近越好，可以把$p_\theta$ 建模为Gaussian :![[Pasted image 20231130100706.png|70]], mean确定后参数确定，从而variance确定
					1. ![[Pasted image 20231130100921.png]]![[Pasted image 20231130100935.png]] $x_\theta$ 由 neural network给出
					2. ![[Pasted image 20231130101050.png]]
					3. ![[Pasted image 20231130101105.png]]
					4. 最后是minimize expectations over all timesteps![[Pasted image 20231130101225.png]]
4. Learning noise parameters
	1. ![[Pasted image 20231130101848.png|120]]由前面推导得SNR，SNR越小Noise越大，希望t增加snr单调减少。
	2. 最终可化简为![[Pasted image 20231130102053.png|291]]![[Pasted image 20231130102103.png]]
	3. 希望构建nn去model snr, 表达为![[Pasted image 20231130102148.png|200]]
5. noise形式
	1. 带入![[Pasted image 20231130102716.png|204]]到 $u_q$ , 得![[Pasted image 20231130102741.png|222]]
	2. 带入KL式
			![[Pasted image 20231130102803.png|300]]
	3. 表示predict x0相当于predict noise.(一些表明predict noise performance更好)
6. 形式
	1. Tweedie’s Formula : "states that the true mean of an exponential family distribution, given samples drawn from it, can be estimated by the maximum likelihood estimate of the samples (aka empirical mean) plus some correction term involving the score of the estimate." 矫正项考虑到sample分布情况![[Pasted image 20231130103552.png|525]]
		 ![[Pasted image 20231130103710.png|359]]
		 ![[Pasted image 20231130103727.png|357]]
	1. 带入$u_q$ 推出: 
		 ![[Pasted image 20231130103834.png]]![[Pasted image 20231130103849.png]]
		 ![[Pasted image 20231130103917.png]]![[Pasted image 20231130103929.png]]$s_\theta(x_t,t)$ is a nn learns to predict the score function $\nabla_{x_t}logp(x_t)$ 
	1. 和原来$\epsilon_0$ 关系？：可见多一个scale项，score function 指导我们如何在数据空间中移动以优化（最大化）目标函数（这里是log p）的作用，intuitively，是添加source noise 的反方向
		1. ![[Pasted image 20231130104036.png]]
	 

### DDPM
#### 扩散

$$
X_t \sim  \mathcal{N}(\sqrt{\alpha_t}X_{t-1},(1-\alpha_t)I)

$$
$$X_t \sim  \mathcal{N}(\sqrt{\bar{\alpha_t}}X_{0},(1-\bar{\alpha_t})I)$$
$$X_t = \sqrt{\alpha_t}X_{t-1} + \sqrt{1-\alpha_t}Z_t$$
$$X_t = \sqrt{\bar{\alpha_t}}X_{0} + \sqrt{(1-\bar{\alpha_t})}Z$$
#### 反向

$$X_{t-1} \sim \mathcal{N}(\mu,\sigma^2)$$ $$\mu =  \sqrt{\alpha_t} \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t}}X_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}X_0 =  \frac{1}{\sqrt{\alpha_t}}(X_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\widetilde Z)$$
$$\sigma^2 = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$$

![[Pasted image 20240223110641.png]]

### DDIM
![[Pasted image 20240301220349.png]]
# ControlNet
## Motivation
1. 希望能用额外的图像特定构图（, edge maps, human pose skeletons, segmentation maps, depth, normals,）
2. 对大型的T2I模型来讲，学习end-to-end条件的控制具有的挑战：
	1. 训练学习特定的条件的训练数据较小，会导致overfitting and catastrophic forgetting
## Contribution
1. 锁定原来参数：
2. 对一部分encoder layer做trainnable copy
3. 两个部分通过zero convolution layer连接（防止有害的噪声干扰diffusion训练）
## Method

![[Pasted image 20240226112350.png]]
$x$:feature map $c$: conditionnal vector
![[Pasted image 20240226112411.png]]
![[Pasted image 20240226112419.png]]
1. 初始zero conv为0，所以$y_c = y$,没有有害的noise可以影响隐藏层
2. trainable copy: 12 encoding blocks,1 moddle block
3. Controlnet结果通过decoder 12个skip connection加在原来网络
4. 注意SD是将512 x 512转为 64x64作为latent images去训练，为了一致需要一个小的网络将条件c也embedd

## Training
1. 用empty string随机替换50%text->增加ControlNet对conditioning image语义识别能力 (??CFG)
2. 一个观察：sudden convergence phenomenon ![[Pasted image 20240227201530.png]]
## Inference
### CFG
![[Pasted image 20240228162258.png]]
conditioning image ：
1. 加在uc和c: 当无prompt时，同时加会移除guidance
2. 加在c: 使得guidance过强，图像过饱和
解决：加在c,并且在加到SD上时根据13个block大小乘上系数，降低image guidance
### 多个controlnet
每个单独训练，最后相加
## Experiments
### Ablative study
说明trainable copy和zero conv有效性 ：1）trainable copy换为conv 2)zero换Gaussian
![[Pasted image 20240228164008.png]]

### 评估
+ user study
+ ADE20K : to evaluate the conditioning fidelity.
+ FID,CLIP-score,CLIP aesthetic score: distribution distance

![[Pasted image 20240228164527.png]]
![[Pasted image 20240228164546.png]]


# DreamBooth
new concept learning(subject-driven)
## Motivation
+ 希望生成具有特定物体的图像：虽然T2I具有语义先验，但输出域表达有限（不能生成same subject,不准确).以往受限于global editing,没法fine-grained control

## Contribution
+ fine-tune T2I :
	+ text prompt带有关于特定物体的identifier，使模型学习到先验，这个先验和特定实体绑定。
	+ 为防止lauguage shift: autogenous, class-specific prior preservation loss

## Method
![[Pasted image 20240301204445.png]]
### T2I
c: conditioning vector
![[Pasted image 20240228180146.png]]
### Personalization
1. 相比于GANs的fine-tune易导致overfit和mode-collapse:
> large text-to-image diffusion models seem to excel at integrating new information into their domain without forgetting the prior or overfitting to a small set of training images.
### Prompt
a \[identifier] \[class noun]
### Identifier
需要identifier在LM和diffusion中都具有weak prior.
+ rare identifier: $f (\hat V)$, f: tockenizer; $\hat V$: decoded text
+ 
### Class-specific Prior Preservation Loss
+ Fine-tune Problem：
	+ finetune 可能带来lauguage drift
		+ (注：LM finetune后失去原先的句法语义知识，diffusion也有相似现象“slowly forgets how to generate subjects of the same class as the target subject”)
	+ 减少了diversity
+ 解决上述两问题：loss
	+ 另外用\[class noun]生成数据 $x_{pr}$
	+ ![[Pasted image 20240228182558.png|500]]
		+ 第二项prior-preservation term:用生成的数据来指导模型，以保持先验信息

## Experiments

评估：
+ subject fidelity:
	+ CLIP-I : average pairwise cosine similarity between CLIP  embeddings of generated and real images(但不能区分高度相似文本的物体)
	+ DINO: 鼓励区分物体独特特征
+ prompt fidelity
	+ CLIP-T: average pairwise cosine similarity between CLIP embeddings of generated and real images
![[Pasted image 20240228183541.png|475]]
在Imagen上比在SD上好

### 消融实验
+ Prior preservation loss
+ class-prior
+ 

### 局限性
+ 没能根据context生成正确背景
	+ 可能这些a weak prior for contexts,或在数据集中这些概念共现概率低
+ context-appearance entanglement：物体跟随背景变化了
+ overfitting to the real images：prompt和training set中图片的setting较像
+ 一些常见的物体更容易学习


# Null-text Inversion
![[Pasted image 20240301204752.png]]
Inversion: 通过优化uncond 中的null-text

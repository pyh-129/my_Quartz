
 1. 编码器 解码器：RNN
	1. 编码器输出context向量 ，长度取决于RNN隐藏神经元数量
	2. RNN处理：
		1. 假设序列输入是一个句子，这个句子可以由$n$个词表示：$sentence = \{w_1, w_2,...,w_n\}$。
		2. RNN首先将句子中的每一个词映射成为一个向量得到一个向量序列：$X = \{x_1, x_2,...,x_n\}$，每个单词映射得到的向量通常又叫做：word embedding。
		3. 然后在处理第$t \in [1,n]$个时间步的序列输入$x_t$时，RNN网络的输入和输出可以表示为：$h_{t} = RNN(x_t, h_{t-1})$

		   - 输入：RNN在时间步$t$的输入之一为单词$w_t$经过映射得到的向量$x_t$。
		   - 输入：RNN另一个输入为上一个时间步$t-1$得到的hidden state向量$h_{t-1}$，同样是一个向量。
		   - 输出：RNN在时间步$t$的输出为$h_t$ hidden state向量。
	3. word embedding?:
		1. 提前训练好 或在自有数据集上训练word
2. 缺点：所有信息编码到一个context向量中，很难包含所有文本序列的信息-> [[002 attention]]
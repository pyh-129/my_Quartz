## 边缘检测
前面几层检测边缘，中间检测物体部分，后面检测完整物体：

filter/kernel, '\*' 这里表示卷积运算
![[Pasted image 20240124144904.png]]
检测了中间竖线的边缘，卷积核表示竖左边是浅颜色，右边是深颜色->边缘竖线

## Padding
kernel:f\*f  最后矩阵大小(n-f+1)\*(n-f+1)  (f一般是奇数 防止不对称过滤，且中间像素点会有帮助)
padding: p 最后矩阵大小（n+2p-f+1)\*(n+2p-f+1)

![[Pasted image 20240124150130.png]]

## 步长Stride

$\lfloor(n+2p-f)/s)+1\rfloor*\lfloor(n+2p-f)/s+1\rfloor$ 
向下取整表示如果kernel未完全覆盖的部分不做计算：![[Pasted image 20240124150754.png]]
## 三维卷积
![[Pasted image 20240124151448.png]]
每个channel 可以有不同的高和宽
![[Pasted image 20240124151716.png]]
$n_c$:通道数 $n_c\prime$: filter个数
output最后一个维度是filter数量
## 单层卷积网络
![[Pasted image 20240124152842.png]]

每个filter有一个Bias

![[Pasted image 20240124152206.png]]

![[Pasted image 20240124152759.png]]
l:l层

## 简单卷积网络
![[Pasted image 20240124153614.png]]
最后展成一维向量，用softmax计算
![[Pasted image 20240124153751.png]]

## 池化层
缩减模型大小，提高计算速度，提高所提取特征的鲁棒性
![[Pasted image 20240124153954.png]]
相当于用f=2,s=2（hyper parameters）的filter，通常不用padding
作用：如果提取到某个特征，取他的最大值
但是no parameters to learn,因为固定了f,s
![[Pasted image 20240124154620.png]]
大量参数存在于fc nn中


一般随着深度增加，高和宽减少，通道数增加

## Why 卷积
相比于fc, convolutional layer好处在于 参数共享 和 稀疏连接：
![[Pasted image 20240206174220.png]]
通过这两种方式减小参数量，当用小数据集训练时预防过拟合
还可以善于捕捉平移不变性（translation invariance)
